# preflight-mcp Environment Variables Example
# Copy this file to .env and fill in your values

# ============================================
# Storage Configuration
# ============================================

# Single storage directory (simple setup)
# PREFLIGHT_STORAGE_DIR=/path/to/bundles

# Multiple storage directories for mirror backup (semicolon-separated)
# Windows: PREFLIGHT_STORAGE_DIRS=D:\cloud1\preflight;E:\cloud2\preflight
# Linux/Mac: PREFLIGHT_STORAGE_DIRS=/path/to/storage1;/path/to/storage2
# PREFLIGHT_STORAGE_DIRS=

# Temporary directory for git checkouts
# PREFLIGHT_TMP_DIR=/tmp/preflight-mcp

# ============================================
# GitHub Configuration
# ============================================

# GitHub Personal Access Token (optional, for higher rate limits and private repos)
# GITHUB_TOKEN=ghp_your_token_here

# Git clone timeout in milliseconds (default: 300000 = 5 minutes)
# PREFLIGHT_GIT_CLONE_TIMEOUT_MS=300000

# ============================================
# Context7 Integration (optional)
# ============================================

# Context7 API Key (optional, enables higher rate limits)
# CONTEXT7_API_KEY=your_context7_api_key

# Context7 MCP endpoint (usually not needed)
# CONTEXT7_MCP_URL=https://mcp.context7.com/mcp

# ============================================
# Bundle Processing Limits
# ============================================

# Maximum size per file in bytes (default: 524288 = 512 KiB)
# PREFLIGHT_MAX_FILE_BYTES=524288

# Maximum total size per repo in bytes (default: 52428800 = 50 MiB)
# PREFLIGHT_MAX_TOTAL_BYTES=52428800

# ============================================
# Static Analysis
# ============================================

# Analysis mode: 'none' | 'quick' | 'full' (default: full)
# PREFLIGHT_ANALYSIS_MODE=full

# ============================================
# Deterministic Parsing (Evidence)
# ============================================

# AST engine: 'wasm' (default) or 'native' (optional acceleration)
# PREFLIGHT_AST_ENGINE=wasm

# ============================================
# Built-in REST API (default enabled)
# ============================================

# Enable/disable REST API server
# PREFLIGHT_HTTP_ENABLED=true

# REST listen host (default: 127.0.0.1; set to 0.0.0.0 for external access)
# PREFLIGHT_HTTP_HOST=127.0.0.1

# REST listen port (default: 37123)
# PREFLIGHT_HTTP_PORT=37123

# ============================================
# Advanced Configuration
# ============================================

# Maximum number of Context7 libraries to process (default: 20)
# PREFLIGHT_MAX_CONTEXT7_LIBRARIES=20

# Maximum number of Context7 topics per library (default: 10)
# PREFLIGHT_MAX_CONTEXT7_TOPICS=10

# Maximum concurrent bundle creation operations (default: 10)
# PREFLIGHT_MAX_CONCURRENT_BUNDLES=10

# Maximum tokens for FTS query (default: 12)
# PREFLIGHT_MAX_FTS_QUERY_TOKENS=12

# Maximum skipped file notes in manifest (default: 50)
# PREFLIGHT_MAX_SKIPPED_NOTES=50

# Default max age in hours before auto-update (default: 24)
# PREFLIGHT_DEFAULT_MAX_AGE_HOURS=24

# Maximum search results limit (default: 200)
# PREFLIGHT_MAX_SEARCH_LIMIT=200

# Default search results limit (default: 30)
# PREFLIGHT_DEFAULT_SEARCH_LIMIT=30

# ============================================
# Semantic Search (Optional Feature)
# ============================================
# Semantic search provides vector-based similarity search using embeddings.
# This is an OPTIONAL feature - disabled by default to maintain zero-dependency design.
# When enabled, you need an embedding provider (Ollama for local, OpenAI for cloud).

# Enable semantic search (default: false)
# PREFLIGHT_SEMANTIC_SEARCH=false

# Embedding provider: 'ollama' (local, default) or 'openai' (cloud)
# PREFLIGHT_EMBEDDING_PROVIDER=ollama

# --- Ollama Configuration (Local, Zero Cloud Dependency) ---
# Ollama server host (default: http://localhost:11434)
# PREFLIGHT_OLLAMA_HOST=http://localhost:11434

# Ollama embedding model (default: nomic-embed-text)
# Recommended models: nomic-embed-text (768d), mxbai-embed-large (1024d), all-minilm (384d)
# PREFLIGHT_OLLAMA_MODEL=nomic-embed-text

# --- OpenAI Configuration (Cloud) ---
# OpenAI API key (required if PREFLIGHT_EMBEDDING_PROVIDER=openai)
# OPENAI_API_KEY=sk-your-api-key

# OpenAI embedding model (default: text-embedding-3-small)
# PREFLIGHT_OPENAI_MODEL=text-embedding-3-small

# OpenAI API base URL (optional, for compatible endpoints like Azure)
# OPENAI_BASE_URL=https://api.openai.com/v1
